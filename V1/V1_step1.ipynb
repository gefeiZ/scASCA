{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "import scanpy as sc\n",
    "import argparse\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CellSNP de novo genotyping "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-sample pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "BAMS=\"/data02/zhaogefei/pbmc_public/GSE163160/pbmc1/SRR13252434_atac/outs/possorted_bam.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/GSE163160/pbmc2/SRR13252435_atac/outs/possorted_bam.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/GSE163160/pbmc3/SRR13252436_atac/outs/possorted_bam.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/GSE163160/pbmc4/SRR13252437_atac/outs/possorted_bam.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/GSE163160/pbmc5/SRR13252438_atac/outs/possorted_bam.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/GSE163160/pbmc6/SRR13252439_atac/outs/possorted_bam.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/10Xpublic/1kng11/1kng11.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/10Xpublic/5kng11/5kng11.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/10Xpublic/10kng11/10kng11.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/10Xpublic/10kv2cc/10kv2cc.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/10Xpublic/10kv2cx/10kv2cx.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/10Xpublic/10kv11cx/10kv11cx.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/10Xpublic/10kv11cxm/10kv11cxm.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/10Xpublic/500ng11/500ng11.bam,\\\n",
    "/data02/zhaogefei/pbmc_public/10Xpublic/10kv11cc/10k_PBMC_ATAC_nextgem_Chromium_Controller_possorted_bam.bam\"\n",
    "\n",
    "\n",
    "OUT_DIR=\"~/denovo_discovery\"\n",
    "mkdir -p ${OUT_DIR}\n",
    "\n",
    "echo \"Starting De Novo SNP Discovery on ALL BAMs...\"\n",
    "\n",
    "\n",
    "# --minMAF 0.05:  min counting allele frequency \n",
    "# --minCOUNT 100: min counting reads supporting SNP\n",
    "# --chrom:  keep only standard chromosomes\n",
    "\n",
    "cellsnp-lite \\\n",
    "    -s ${BAMS} \\\n",
    "    -O ${OUT_DIR} \\\n",
    "    --minMAF 0.05 \\\n",
    "    --minCOUNT 100 \\\n",
    "    --chrom chr1,chr2,chr3,chr4,chr5,chr6,chr7,chr8,chr9,chr10,chr11,chr12,chr13,chr14,chr15,chr16,chr17,chr18,chr19,chr20,chr21,chr22,chrX,chrY \\\n",
    "    --cellTAG None \\\n",
    "    --UMItag None \\\n",
    "    -p 24 \\\n",
    "    --genotype \\\n",
    "    --gzip\n",
    "\n",
    "echo \"Done! The dictionary file is located at: ${OUT_DIR}/cellSNP.base.vcf.gz\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import sys\n",
    "import os\n",
    "\n",
    "\n",
    "DENOVO_FILE = \"~/denovo_discovery/cellSNP.base.vcf.gz\"\n",
    "# Reference dbSBP or 1KG VCF\n",
    "REF_FILE = \"broad_hg38.vcf.gz\"\n",
    "\n",
    "OUT_FILE = \"~/denovo_discovery/cellSNP.filtered_1kG.vcf.gz\"\n",
    "# ===========================================\n",
    "\n",
    "def filter_vcf():\n",
    "    print(f\"Start filtering...\")\n",
    "    print(f\"Input: {DENOVO_FILE}\")\n",
    "    print(f\"Reference: {REF_FILE}\")\n",
    "\n",
    "    ref_sites = set()\n",
    "    print(\"Loading Reference positions into memory...\")\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(REF_FILE, 'rt') as f:\n",
    "            for line in f:\n",
    "                if line.startswith(\"#\"): continue\n",
    "                parts = line.split('\\t', 2)\n",
    "            \n",
    "                ref_sites.add(f\"{parts[0]}:{parts[1]}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading reference: {e}\")\n",
    "        return\n",
    "\n",
    "    print(f\"Loaded {len(ref_sites)} sites from Reference.\")\n",
    "\n",
    "\n",
    "    print(\"Filtering De Novo variants...\")\n",
    "    kept_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    try:\n",
    "        with gzip.open(DENOVO_FILE, 'rt') as fin, gzip.open(OUT_FILE, 'wt') as fout:\n",
    "            for line in fin:\n",
    "              \n",
    "                if line.startswith(\"#\"):\n",
    "                    fout.write(line)\n",
    "                    continue\n",
    "                total_count += 1\n",
    "                parts = line.split('\\t', 2)\n",
    "                key = f\"{parts[0]}:{parts[1]}\"\n",
    "            \n",
    "                if key in ref_sites:\n",
    "                    fout.write(line)\n",
    "                    kept_count += 1\n",
    "\n",
    "                if total_count % 100000 == 0:\n",
    "                    print(f\"Processed {total_count} lines, kept {kept_count}...\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing de novo file: {e}\")\n",
    "        return\n",
    "\n",
    "    print(\"=\"*30)\n",
    "    print(\"Done!\")\n",
    "    print(f\"Total De Novo variants: {total_count}\")\n",
    "    print(f\"Variants kept (in 1kG): {kept_count}\")\n",
    "    print(f\"Output saved to: {OUT_FILE}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    filter_vcf()\n",
    "\n",
    "#RUN BASH SCRIPT TO EXECUTE THE PIPELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# The saame as first demonstration but with barcode files added\n",
    "# Format: SAMPLE  BAM FILE  CELLTAG  BARCODE FILE\n",
    "BAM_LIST=\"bam_list.tsv\" \n",
    "OUT_BASE=\"~/cellsnp_pre_sampler\"\n",
    "VCF_FILE=\"~/denovo_discovery/cellSNP.filtered_1kG.vcf.gz\"\n",
    "\n",
    "mkdir -p ${OUT_BASE}\n",
    "\n",
    "echo \"==========================================\"\n",
    "echo \"Starting cellsnp-lite processing\"\n",
    "echo \"BAM list: ${BAM_LIST}\"\n",
    "echo \"Output base: ${OUT_BASE}\"\n",
    "echo \"VCF file: ${VCF_FILE}\"\n",
    "echo \"==========================================\"\n",
    "\n",
    "\n",
    "while read SAMPLE BAM CELLTAG BARCODE_FILE; do\n",
    "    echo \">>> Processing ${SAMPLE} (${CELLTAG})\"\n",
    "    echo \"   BAM: ${BAM}\"\n",
    "    echo \"   Barcode file: ${BARCODE_FILE}\"\n",
    "\n",
    "    if [ ! -f \"${BAM}\" ]; then\n",
    "        echo \"   ERROR: BAM file not found: ${BAM}\"\n",
    "        echo \"   Skipping ${SAMPLE}\"\n",
    "        continue\n",
    "    fi\n",
    "    \n",
    "    if [ ! -f \"${BARCODE_FILE}\" ]; then\n",
    "        echo \"   ERROR: Barcode file not found: ${BARCODE_FILE}\"\n",
    "        echo \"   Skipping ${SAMPLE}\"\n",
    "        continue\n",
    "    fi\n",
    "    \n",
    "    BARCODE_COUNT=$(wc -l < \"${BARCODE_FILE}\" 2>/dev/null || echo 0)\n",
    "    if [ \"${BARCODE_COUNT}\" -eq 0 ]; then\n",
    "        echo \"   WARNING: Barcode file is empty: ${BARCODE_FILE}\"\n",
    "        echo \"   Skipping ${SAMPLE}\"\n",
    "        continue\n",
    "    fi\n",
    "    \n",
    "    OUT_DIR=${OUT_BASE}/${SAMPLE}\n",
    "    mkdir -p ${OUT_DIR}\n",
    "    \n",
    "    echo \"   Barcodes: ${BARCODE_COUNT}\"\n",
    "    echo \"   Output dir: ${OUT_DIR}\"\n",
    "    echo \"   Running cellsnp-lite...\"\n",
    "    \n",
    "    cellsnp-lite \\\n",
    "        -s ${BAM} \\\n",
    "        -b ${BARCODE_FILE} \\\n",
    "        -O ${OUT_DIR} \\\n",
    "        -R ${VCF_FILE} \\\n",
    "        --cellTAG ${CELLTAG} \\\n",
    "        --UMItag None \\\n",
    "        --minMAF 0 \\\n",
    "        --minCOUNT 0 \\\n",
    "        --chrom chr1,chr2,chr3,chr4,chr5,chr6,chr7,chr8,chr9,chr10,chr11,chr12,chr13,chr14,chr15,chr16,chr17,chr18,chr19,chr20,chr21,chr22 \\\n",
    "        -p 20 \\\n",
    "        --genotype \n",
    "\n",
    "    \n",
    "done < ${BAM_LIST}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vireo For Donors discoverey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io as sio\n",
    "from scipy.sparse import hstack\n",
    "import numpy as np\n",
    "#import gzip\n",
    "import shutil\n",
    "\n",
    "BASE_DIR = \"~/cellsnp_pre_sampler\"\n",
    "\n",
    "\n",
    "OUT_DIR = \"~/cellsnp_pre_sampler/merged_output\"\n",
    "\n",
    "# BASE_DIR/sample0, BASE_DIR/sample1\n",
    "SAMPLES = ['SRR13252434',\n",
    " 'SRR13252435',\n",
    " 'SRR13252436',\n",
    " 'SRR13252437',\n",
    " 'SRR13252438',\n",
    " 'SRR13252439',\n",
    " '1kng11',\n",
    " '5kng11',\n",
    " '10kng11',\n",
    " '10kv2cc',\n",
    " '10kv2cx',\n",
    " '10kv11cx',\n",
    " '10kv11cxm',\n",
    " '500ng11',\n",
    " '10kv11cc',\n",
    "]\n",
    "# ===========================================\n",
    "\n",
    "def merge_cellsnp_outputs():\n",
    "    \n",
    "    if not os.path.exists(OUT_DIR):\n",
    "        os.makedirs(OUT_DIR)\n",
    "        print(f\"Created output directory: {OUT_DIR}\")\n",
    "\n",
    "    ad_matrices = []\n",
    "    dp_matrices = []\n",
    "    all_barcodes = []\n",
    "    \n",
    "    n_rows_check = None\n",
    "\n",
    "\n",
    "\n",
    "    for sample in SAMPLES:\n",
    "        sample_path = os.path.join(BASE_DIR, sample)\n",
    "        print(f\"Processing: {sample} ...\")\n",
    "\n",
    "    \n",
    "        try:\n",
    "            ad = sio.mmread(os.path.join(sample_path, \"cellSNP.tag.AD.mtx\")).tocsr()\n",
    "            dp = sio.mmread(os.path.join(sample_path, \"cellSNP.tag.DP.mtx\")).tocsr()\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Error: No {sample} .mtx files, PASS\")\n",
    "            continue\n",
    "\n",
    "       \n",
    "        if n_rows_check is None:\n",
    "            n_rows_check = ad.shape[0]\n",
    "        else:\n",
    "            if ad.shape[0] != n_rows_check:\n",
    "                raise ValueError(\n",
    "                    f\"Should have same SNP rows!\"\n",
    "                )\n",
    "\n",
    "   \n",
    "        bc_file = os.path.join(sample_path, \"cellSNP.samples.tsv\")\n",
    "        with open(bc_file, 'r') as f:\n",
    "            bcs = [line.strip() for line in f]\n",
    "        \n",
    "        bcs_modified = [f\"{sample}_{bc}\" for bc in bcs]\n",
    "\n",
    "       \n",
    "        if len(bcs_modified) != ad.shape[1]:\n",
    "            raise ValueError(f\"Sample {sample} Barcodes numbers not match AD matrix columns!\")\n",
    "\n",
    "    \n",
    "        ad_matrices.append(ad)\n",
    "        dp_matrices.append(dp)\n",
    "        all_barcodes.extend(bcs_modified)\n",
    "\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"SANPLES: {len(ad_matrices)}\")\n",
    "    print(f\"SNPs per sample (Rows): {n_rows_check}\")\n",
    "    print(f\"BARCODES (Cols): {len(all_barcodes)}\")\n",
    "    \n",
    "\n",
    "    print(\"Horizontal Stack...\")\n",
    "    merged_ad = hstack(ad_matrices)\n",
    "    merged_dp = hstack(dp_matrices)\n",
    "\n",
    "\n",
    "    print(f\"TO {OUT_DIR} ...\")\n",
    "    sio.mmwrite(os.path.join(OUT_DIR, \"cellSNP.tag.AD.mtx\"), merged_ad)\n",
    "    sio.mmwrite(os.path.join(OUT_DIR, \"cellSNP.tag.DP.mtx\"), merged_dp)\n",
    "    with open(os.path.join(OUT_DIR, \"cellSNP.samples.tsv\"), 'w') as f:\n",
    "        for bc in all_barcodes:\n",
    "            f.write(bc + \"\\n\")\n",
    "\n",
    "    first_vcf = os.path.join(BASE_DIR, SAMPLES[0], \"cellSNP.base.vcf\")\n",
    "    target_vcf = os.path.join(OUT_DIR, \"cellSNP.base.vcf\")\n",
    "    \n",
    "    if os.path.exists(first_vcf):\n",
    "        shutil.copy(first_vcf, target_vcf)\n",
    "        print(\"WELL DONE: VCF file copied to output directory.\")\n",
    "    else:\n",
    "        print(\"NO VCF file found to copy.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    merge_cellsnp_outputs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "CELLSNP_DIR=\"~/cellsnp_pre_sampler/merged_output\"\n",
    "\n",
    "\n",
    "OUT_DIR=\"~/Vireo\"\n",
    "mkdir -p $OUT_DIR\n",
    "\n",
    "# -c: cellsnp-lite output dir (AFTER MERGE)\n",
    "# -N: how many samples to deconvolute (DONOR NUMBER)\n",
    "# -o: out dir\n",
    "# -p: task per CPU\n",
    "\n",
    "vireo -c $CELLSNP_DIR -N 8 -o $OUT_DIR -p 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indentity cancidate ASA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ON SUB CELLTYPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adata=sc.read_h5ad('CD4_T_subfilter.h5ad')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Donor Aggregation\n",
    "Strict Reads Imbalance on SNV positon (Check snv position coverage)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "vireo_df=pd.read_csv(\"~/donor_ids.tsv\", sep=\"\\t\", index_col=0)\n",
    "if isinstance(adata.X, np.ndarray):\n",
    "    counts = adata.X.sum(axis=1)\n",
    "else:\n",
    "    counts = adata.X.sum(axis=1).A1  \n",
    "\n",
    "adata.obs['total_fragments'] = counts\n",
    "\n",
    "common_cells = adata.obs_names.intersection(vireo_df.index)\n",
    "meta_df = pd.DataFrame(index=common_cells)\n",
    "meta_df['donor_id'] = vireo_df.loc[common_cells, 'donor_id']\n",
    "meta_df['total_fragments'] = adata.obs.loc[common_cells, 'total_fragments']\n",
    "meta_df = meta_df[~meta_df['donor_id'].isin(['unassigned', 'doublet'])]\n",
    "meta_df.to_csv(\"cell_meta.tsv\", sep=\"\\t\", index_label=\"cell\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#meta_path = \"cell_meta.tsv\"\n",
    "#meta_df = pd.read_csv(meta_path, sep=\"\\t\", index_col=0)\n",
    "TARGET_CELL_TYPE = \"cd4\" \n",
    "\n",
    "\n",
    "target_barcodes = meta_df.index.values\n",
    "\n",
    "# ==========================================\n",
    "print(\"Loading VCF...\")\n",
    "vcf_df = pd.read_csv(\"~/cellsnp_pre_sampler/merged_output/cellSNP.base.vcf.gz\", \n",
    "                     sep=\"\\t\", comment='#', header=None, compression='gzip')\n",
    "snp_ids = (vcf_df[0].astype(str) + \"_\" + vcf_df[1].astype(str) + \"_\" + \n",
    "           vcf_df[3].astype(str) + \"_\" + vcf_df[4].astype(str)).values\n",
    "\n",
    "\n",
    "print(\"Loading Matrices...\")\n",
    "ad_mtx = sio.mmread(\"~/cellsnp_pre_sampler/merged_output/cellSNP.tag.AD.mtx\").tocsr()\n",
    "dp_mtx = sio.mmread(\"~/cellsnp_pre_sampler/merged_output/cellSNP.tag.DP.mtx\").tocsr()\n",
    "matrix_barcodes = pd.read_csv(\"~/cellsnp_pre_sampler/merged_output/cellSNP.samples.tsv\", header=None)[0].values\n",
    "\n",
    "# SLICE\n",
    "print(\"Slicing matrix for target cells...\")\n",
    "_, matrix_idx, target_idx = np.intersect1d(matrix_barcodes, target_barcodes, return_indices=True)\n",
    "\n",
    "if len(matrix_idx) == 0:\n",
    "    raise ValueError(\"ERROR:CHECK BARCODE\")\n",
    "\n",
    "ad_mtx_sub = ad_mtx[:, matrix_idx]\n",
    "dp_mtx_sub = dp_mtx[:, matrix_idx]\n",
    "barcode_to_donor = meta_df['donor_id'].to_dict()\n",
    "sub_donors = np.array([barcode_to_donor[bc] for bc in matrix_barcodes[matrix_idx]])\n",
    "\n",
    "# ==========================================\n",
    "\n",
    "results = []\n",
    "unique_donors = np.unique(sub_donors)\n",
    "\n",
    "for snp_idx in tqdm(range(ad_mtx_sub.shape[0])):\n",
    "    row_dp = dp_mtx_sub[snp_idx, :].toarray().flatten()\n",
    "    if row_dp.sum() == 0: continue\n",
    "    \n",
    "    row_ad = ad_mtx_sub[snp_idx, :].toarray().flatten()\n",
    "    current_snp_id = snp_ids[snp_idx] \n",
    "    \n",
    "    for donor in unique_donors:\n",
    "        donor_mask = (sub_donors == donor)\n",
    "        valid_mask = donor_mask & (row_dp > 0)\n",
    "        \n",
    "        if not np.any(valid_mask): continue\n",
    "        \n",
    "        count_pos = row_ad[valid_mask].sum()\n",
    "        count_total = row_dp[valid_mask].sum()\n",
    "        count_neg = count_total - count_pos\n",
    "        n_cells = np.sum(valid_mask)\n",
    "        \n",
    "        if count_total < 10 or n_cells < 5: continue\n",
    "        \n",
    "        results.append({\n",
    "            \"SNP\": current_snp_id,\n",
    "            \"CellType\": TARGET_CELL_TYPE,\n",
    "            \"Donor\": donor,\n",
    "            \"Count_Pos\": count_pos,\n",
    "            \"Count_Neg\": count_neg,\n",
    "            \"N_Cells\": n_cells\n",
    "        })\n",
    "\n",
    "df_final = pd.DataFrame(results)\n",
    "\n",
    "#print(df_final.head())\n",
    "#              SNP CellType   Donor  Count_Pos  Count_Neg  N_Cells\n",
    "#  chr1_10231_C_A      cd4  donor5          5          5       10\n",
    "#  chr1_10291_C_T      cd4  donor4          0         11       10\n",
    "#  chr1_10291_C_T      cd4  donor5          5         37       38\n",
    "#  chr1_10327_T_C      cd4  donor4          3         10       12\n",
    "#  chr1_10327_T_C      cd4  donor5          1         16       15\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peak_names = adata.var_names \n",
    "\n",
    "\n",
    "peak_data = []\n",
    "for p in peak_names:\n",
    "    parts = p.replace(\":\", \"-\").split(\"-\")\n",
    "    peak_data.append({\n",
    "        \"chrom\": parts[0],\n",
    "        \"start\": int(parts[1]),\n",
    "        \"end\": int(parts[2]),\n",
    "        \"peak_id\": p  \n",
    "    })\n",
    "\n",
    "df_peaks = pd.DataFrame(peak_data)\n",
    "\n",
    "print(\"Mapping SNPs to Peaks (Robust Method)...\")\n",
    "\n",
    "\n",
    "snp_meta = df_final['SNP'].str.split('_', expand=True)\n",
    "df_final['chrom'] = snp_meta[0]\n",
    "df_final['pos'] = snp_meta[1].astype(int)\n",
    "peak_data = []\n",
    "for p in peak_names:\n",
    "    parts = p.replace(\":\", \"-\").split(\"-\")\n",
    "    peak_data.append({\n",
    "        \"chrom\": parts[0],\n",
    "        \"start\": int(parts[1]),\n",
    "        \"end\": int(parts[2]),\n",
    "        \"peak_id\": p\n",
    "    })\n",
    "df_peaks = pd.DataFrame(peak_data)\n",
    "\n",
    "mapped_results = []\n",
    "\n",
    "for chrom in df_final['chrom'].unique():\n",
    "    \n",
    "\n",
    "    subset_snps = df_final[df_final['chrom'] == chrom]\n",
    "    subset_peaks = df_peaks[df_peaks['chrom'] == chrom]\n",
    "    \n",
    "    if subset_snps.empty or subset_peaks.empty: continue\n",
    "\n",
    "    subset_snps = subset_snps.sort_values('pos')\n",
    "    snp_pos = subset_snps['pos'].values\n",
    "    peak_starts = subset_peaks['start'].values\n",
    "    peak_ends = subset_peaks['end'].values\n",
    "    peak_ids = subset_peaks['peak_id'].values\n",
    "    \n",
    "\n",
    "    left_idxs = np.searchsorted(snp_pos, peak_starts, side='left')\n",
    "    right_idxs = np.searchsorted(snp_pos, peak_ends, side='right')\n",
    "    \n",
    "   \n",
    "    for i in range(len(peak_ids)):\n",
    "        l, r = left_idxs[i], right_idxs[i]\n",
    "      \n",
    "        if r > l:\n",
    "            matched_rows = subset_snps.iloc[l:r].copy()\n",
    "            matched_rows['Peak'] = peak_ids[i]\n",
    "            mapped_results.append(matched_rows)\n",
    "\n",
    "\n",
    "if len(mapped_results) > 0:\n",
    "    df_mapped = pd.concat(mapped_results)\n",
    "    df_export = df_mapped.rename(columns={\"N_Cells\": \"N_Pos\"})\n",
    "    final_cols = [\"SNP\", \"Peak\", \"Donor\", \"N_Pos\",\"Count_Pos\", \"Count_Neg\"]\n",
    "    df_export = df_export[final_cols]\n",
    "    \n",
    "    print(f\"Successfully mapped {len(df_export)} SNP-Peak pairs.\")\n",
    "    output_file = \"asca_counts_input_cd4.csv\"\n",
    "    df_export.to_csv(output_file, sep=\"\\t\", index=False)\n",
    "    print(f\"Saved to {output_file}\")\n",
    "else:\n",
    "    print(\"Warning: No SNPs fell within the provided Peaks.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#              SNP             Peak   Donor  N_Pos  N_Neg  Count_Pos  Count_Neg\n",
    "#  chr1_10231_C_A  chr1:9908-10409  donor5     10      0          5          5\n",
    "#  chr1_10291_C_T  chr1:9908-10409  donor4     10      0          0         11\n",
    "#  chr1_10291_C_T  chr1:9908-10409  donor5     38      0          5         37\n",
    "#  chr1_10327_T_C  chr1:9908-10409  donor4     12      0          3         10\n",
    "#  chr1_10327_T_C  chr1:9908-10409  donor5     15      0          1         16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHECK FOR NEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import scipy.io as sio\n",
    "\n",
    "\n",
    "TARGET_CELL_TYPE = \"cd4\" \n",
    "\n",
    "target_barcodes = meta_df.index.values\n",
    "\n",
    "print(\"Loading VCF...\")\n",
    "vcf_df = pd.read_csv(\"~/cellsnp_pre_sampler/merged_output/cellSNP.base.vcf.gz\", \n",
    "                     sep=\"\\t\", comment='#', header=None, compression='gzip')\n",
    "snp_ids = (vcf_df[0].astype(str) + \"_\" + vcf_df[1].astype(str) + \"_\" + \n",
    "           vcf_df[3].astype(str) + \"_\" + vcf_df[4].astype(str)).values\n",
    "\n",
    "\n",
    "print(\"Loading Matrices...\")\n",
    "ad_mtx = sio.mmread(\"~/cellsnp_pre_sampler/merged_output/cellSNP.tag.AD.mtx\").tocsr()\n",
    "dp_mtx = sio.mmread(\"~/cellsnp_pre_sampler/merged_output/cellSNP.tag.DP.mtx\").tocsr()\n",
    "\n",
    "\n",
    "matrix_barcodes = pd.read_csv(\"~/cellsnp_pre_sampler/merged_output/cellSNP.samples.tsv\", header=None)[0].values\n",
    "\n",
    "print(\"Slicing matrix for target cells...\")\n",
    "_, matrix_idx, target_idx = np.intersect1d(matrix_barcodes, target_barcodes, return_indices=True)\n",
    "\n",
    "if len(matrix_idx) == 0:\n",
    "    raise ValueError(\"CHECK BARCODE FORMAT\")\n",
    "\n",
    "\n",
    "ad_mtx_sub = ad_mtx[:, matrix_idx]\n",
    "dp_mtx_sub = dp_mtx[:, matrix_idx]\n",
    "\n",
    "\n",
    "barcode_to_donor = meta['donor_id'].to_dict()\n",
    "sub_donors = np.array([barcode_to_donor[bc] for bc in matrix_barcodes[matrix_idx]])\n",
    "\n",
    "print(f\"NUM.CELLS {ad_mtx_sub.shape[1]}\")\n",
    "\n",
    "results = []\n",
    "unique_donors = np.unique(sub_donors)\n",
    "\n",
    "for snp_idx in tqdm(range(ad_mtx_sub.shape[0])):\n",
    "    row_dp = dp_mtx_sub[snp_idx, :].toarray().flatten()\n",
    "    if row_dp.sum() == 0: continue\n",
    "    \n",
    "    row_ad = ad_mtx_sub[snp_idx, :].toarray().flatten()\n",
    "    current_snp_id = snp_ids[snp_idx] \n",
    "    \n",
    "    for donor in unique_donors:\n",
    "        donor_mask = (sub_donors == donor)\n",
    "        valid_mask = donor_mask & (row_dp > 0)\n",
    "        \n",
    "        if not np.any(valid_mask): continue\n",
    "        \n",
    "        count_pos = row_ad[valid_mask].sum()\n",
    "        count_total = row_dp[valid_mask].sum()\n",
    "        count_neg = count_total - count_pos\n",
    "        n_cells = np.sum(valid_mask)\n",
    "        \n",
    "        if count_total < 10 or n_cells < 5: continue\n",
    "        \n",
    "        results.append({\n",
    "            \"SNP\": current_snp_id,\n",
    "            \"CellType\": TARGET_CELL_TYPE,\n",
    "            \"Donor\": donor,\n",
    "            \"Count_Pos\": count_pos,\n",
    "            \"Count_Neg\": count_neg,\n",
    "            \"N_Cells\": n_cells\n",
    "        })\n",
    "\n",
    "df_final = pd.DataFrame(results)\n",
    "print(df_final.head())\n",
    "\n",
    "#SAVE\n",
    "# df_final.to_csv(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bio2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
